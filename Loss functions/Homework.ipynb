{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание по теме \"Функции потерь и оптимизация\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Цель:*** оптимизировать самостоятельно реализованную логистическую регрессию.   \n",
    "***Задачи:***\n",
    "- реализовать логистическую регрессию\n",
    "- обучить ее методом градиентного спуска\n",
    "- методом nesterov momentum\n",
    "- методом rmsprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***План*** (в основном совпадает с задачами):\n",
    "1. Изучить данные и предобработать их (проверить на пропуски; оставить только 2 класса - Iris Versicolor и Iris Virginica; проверить баланс классов)  \n",
    "2. Написать функцию логистической регрессии, вручную подобрав коэффициенты; вызвать функцию, проверить качество обучения.  \n",
    "3. Написать функцию градиентного спуска, обучить модель этим методом, проверить score.  \n",
    "4. Написать функцию nesterov momentum, обучить модель этим методом, проверить score.  \n",
    "5. Написать функцию для метода rmsprop, обучить модель этим методом, проверить score.  \n",
    "6. Оформить выводы; выбрать наиболее успешный метод оптимизации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 1. Изучение и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Познакомимся с датасетом \"Ирисы\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = 'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(iris, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"]\n",
    "df.columns = attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width        class\n",
       "0           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "1           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "2           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "3           5.0          3.6           1.4          0.2  Iris-setosa\n",
       "4           5.4          3.9           1.7          0.4  Iris-setosa"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 149 entries, 0 to 148\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  149 non-null    float64\n",
      " 1   sepal_width   149 non-null    float64\n",
      " 2   petal_length  149 non-null    float64\n",
      " 3   petal_width   149 non-null    float64\n",
      " 4   class         149 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 5.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, сколько разных классов используется в потенциальном целевом признаке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Согласно условиям задачи, класс 'Iris-setosa' нам не нужен. Удалим строки, где в качестве целевого признака указан этот класс:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['class'] == 'Iris-setosa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['class'] != 'Iris-setosa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 49 to 148\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  100 non-null    float64\n",
      " 1   sepal_width   100 non-null    float64\n",
      " 2   petal_length  100 non-null    float64\n",
      " 3   petal_width   100 non-null    float64\n",
      " 4   class         100 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 4.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width            class\n",
       "49           7.0          3.2           4.7          1.4  Iris-versicolor\n",
       "50           6.4          3.2           4.5          1.5  Iris-versicolor\n",
       "51           6.9          3.1           4.9          1.5  Iris-versicolor\n",
       "52           5.5          2.3           4.0          1.3  Iris-versicolor\n",
       "53           6.5          2.8           4.6          1.5  Iris-versicolor"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В принципе, это не очень важно, но мы можем сбросить индексы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width            class\n",
       "0           7.0          3.2           4.7          1.4  Iris-versicolor\n",
       "1           6.4          3.2           4.5          1.5  Iris-versicolor\n",
       "2           6.9          3.1           4.9          1.5  Iris-versicolor\n",
       "3           5.5          2.3           4.0          1.3  Iris-versicolor\n",
       "4           6.5          2.8           4.6          1.5  Iris-versicolor"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь перекодируем столбец \"class\" и обозначим его как целевой признак:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "dtype: int32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lec = LabelEncoder()\n",
    "lec.fit(df['class'])\n",
    "target = pd.Series(data=lec.transform(df['class']))\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95    1\n",
       "96    1\n",
       "97    1\n",
       "98    1\n",
       "99    1\n",
       "dtype: int32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим баланс классов в таргете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    50\n",
       "0    50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Баланс идеален. Такое вряд ли встретится в реальной жизни.  \n",
    "Идем дальше: проверим на наличие пропусков остальные столбцы фрейма и обозначим их как фичи (к слову, с типами данных всё в порядке):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    0\n",
       "sepal_width     0\n",
       "petal_length    0\n",
       "petal_width     0\n",
       "class           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           7.0          3.2           4.7          1.4\n",
       "1           6.4          3.2           4.5          1.5\n",
       "2           6.9          3.1           4.9          1.5\n",
       "3           5.5          2.3           4.0          1.3\n",
       "4           6.5          2.8           4.6          1.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.drop('class', axis=1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборку на обучающую и тестовую:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 4)\n",
      "(30, 4)\n",
      "(70,)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_train.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично! Данные готовы к обучению. Переходим ко второму шагу - напишем функцию логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 2. Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем простую функцию логистической регрессии, принимающую на вход строку фичей и подобранные вручную коэффициенты. Для каждой строки расчитаем по формуле лог регрессии прогнозное значение, которое и вернем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(row, coefficients):\n",
    "    y_hat = coefficients[0]        # упростим формулу, разбив ее на несколько строк\n",
    "    for i in range(len(row)):\n",
    "        y_hat += coefficients[i + 1] * row[i]\n",
    "    return 1.0 / (1.0 + np.exp(-y_hat))   # найдем прогнозное значение, используя производную функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рандомным способом выберем 5 коэффициентов для расчета прогноза:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand_coef = np.random.default_rng().random(5)\n",
    "# rand_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из всех вариантов перебора наиболее выигрышными были те, что зафиксированы в ячейке ниже (с отрицательными значениями немного поиграла вручную):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.30362818, -0.80180026, 0.55469071, 0.749991, -0.00459491]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = [-0.30362818, -0.80180026, 0.55469071, 0.749991, -0.00459491]\n",
    "coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вызовем функцию логистической регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted=0.443 [0]\n",
      "Predicted=0.390 [0]\n",
      "Predicted=0.438 [0]\n",
      "Predicted=0.466 [0]\n",
      "Predicted=0.607 [1]\n",
      "Predicted=0.512 [1]\n",
      "Predicted=0.566 [1]\n",
      "Predicted=0.575 [1]\n",
      "Predicted=0.535 [1]\n",
      "Predicted=0.559 [1]\n",
      "Predicted=0.437 [0]\n",
      "Predicted=0.598 [1]\n",
      "Predicted=0.394 [0]\n",
      "Predicted=0.469 [0]\n",
      "Predicted=0.433 [0]\n",
      "Predicted=0.381 [0]\n",
      "Predicted=0.565 [1]\n",
      "Predicted=0.346 [0]\n",
      "Predicted=0.506 [1]\n",
      "Predicted=0.483 [0]\n",
      "Predicted=0.353 [0]\n",
      "Predicted=0.391 [0]\n",
      "Predicted=0.405 [0]\n",
      "Predicted=0.485 [0]\n",
      "Predicted=0.368 [0]\n",
      "Predicted=0.576 [1]\n",
      "Predicted=0.498 [0]\n",
      "Predicted=0.602 [1]\n",
      "Predicted=0.392 [0]\n",
      "Predicted=0.481 [0]\n",
      "Predicted=0.627 [1]\n",
      "Predicted=0.610 [1]\n",
      "Predicted=0.620 [1]\n",
      "Predicted=0.362 [0]\n",
      "Predicted=0.724 [1]\n",
      "Predicted=0.656 [1]\n",
      "Predicted=0.470 [0]\n",
      "Predicted=0.532 [1]\n",
      "Predicted=0.507 [1]\n",
      "Predicted=0.510 [1]\n",
      "Predicted=0.483 [0]\n",
      "Predicted=0.478 [0]\n",
      "Predicted=0.513 [1]\n",
      "Predicted=0.318 [0]\n",
      "Predicted=0.657 [1]\n",
      "Predicted=0.542 [1]\n",
      "Predicted=0.547 [1]\n",
      "Predicted=0.369 [0]\n",
      "Predicted=0.603 [1]\n",
      "Predicted=0.619 [1]\n",
      "Predicted=0.563 [1]\n",
      "Predicted=0.609 [1]\n",
      "Predicted=0.313 [0]\n",
      "Predicted=0.308 [0]\n",
      "Predicted=0.427 [0]\n",
      "Predicted=0.521 [1]\n",
      "Predicted=0.344 [0]\n",
      "Predicted=0.390 [0]\n",
      "Predicted=0.470 [0]\n",
      "Predicted=0.599 [1]\n",
      "Predicted=0.425 [0]\n",
      "Predicted=0.604 [1]\n",
      "Predicted=0.673 [1]\n",
      "Predicted=0.576 [1]\n",
      "Predicted=0.582 [1]\n",
      "Predicted=0.519 [1]\n",
      "Predicted=0.605 [1]\n",
      "Predicted=0.380 [0]\n",
      "Predicted=0.589 [1]\n",
      "Predicted=0.589 [1]\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "for row in features_train.to_numpy():\n",
    "    yhat = log_reg(row, coef)\n",
    "    print(\"Predicted=%.3f [%d]\" % (yhat, round(yhat)))\n",
    "    pred.append(round(yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сравним тергеты и предсказанные значения, вычислив долю правильных ответов. Для этого напишем функцию, создающую матрицу правильных и неправильных ответов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_confusion_matrix(y_true, y_pred):\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if (y_true[i] == 1) & (y_pred[i] == 1):\n",
    "            TP += 1\n",
    "        elif (y_true[i] == 1) & (y_pred[i] == 0):\n",
    "            FN += 1\n",
    "        elif (y_true[i] == 0) & (y_pred[i] == 1):\n",
    "            FP += 1\n",
    "        else:\n",
    "            TN += 1\n",
    "         \n",
    "    return np.array([[TN,FP],[FN,TP]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  5],\n",
       "       [ 5, 32]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matr = my_confusion_matrix(target_train.reset_index(drop=True), pred)\n",
    "conf_matr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перепроверим себя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  5],\n",
       "       [ 5, 32]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(target_train.reset_index(drop=True), pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша функция сработала верно. При условии вручную подобранных коэффициентов ошибок первого и второго рода сравнительно немного.  \n",
    "Теперь всё готово для подсчёта доли правильных ответов - accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "def accuracy(matrix_error):\n",
    "    true_answers = matrix_error[0][0] + matrix_error[1][1]\n",
    "    return true_answers / sum(sum(matrix_error))\n",
    "\n",
    "print(\"Accuracy:\", accuracy(conf_matr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перепроверим себя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(target_train, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, всё посчитано верно. Таким образом, можно сказать, что на обучающей выборке доля правильных ответов достаточно высока (для ручного перебора весов). Проверим теперь работу модели на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted=0.504 [1]\n",
      "Predicted=0.610 [1]\n",
      "Predicted=0.551 [1]\n",
      "Predicted=0.484 [0]\n",
      "Predicted=0.462 [0]\n",
      "Predicted=0.418 [0]\n",
      "Predicted=0.426 [0]\n",
      "Predicted=0.471 [0]\n",
      "Predicted=0.358 [0]\n",
      "Predicted=0.349 [0]\n",
      "Predicted=0.335 [0]\n",
      "Predicted=0.369 [0]\n",
      "Predicted=0.452 [0]\n",
      "Predicted=0.550 [1]\n",
      "Predicted=0.558 [1]\n",
      "Predicted=0.373 [0]\n",
      "Predicted=0.468 [0]\n",
      "Predicted=0.534 [1]\n",
      "Predicted=0.289 [0]\n",
      "Predicted=0.352 [0]\n",
      "Predicted=0.552 [1]\n",
      "Predicted=0.535 [1]\n",
      "Predicted=0.352 [0]\n",
      "Predicted=0.373 [0]\n",
      "Predicted=0.462 [0]\n",
      "Predicted=0.340 [0]\n",
      "Predicted=0.506 [1]\n",
      "Predicted=0.443 [0]\n",
      "Predicted=0.486 [0]\n",
      "Predicted=0.523 [1]\n"
     ]
    }
   ],
   "source": [
    "pred_test = []\n",
    "for row in features_test.to_numpy():\n",
    "    yhat_test = log_reg(row, coef)\n",
    "    print(\"Predicted=%.3f [%d]\" % (yhat_test, round(yhat_test)))\n",
    "    pred_test.append(round(yhat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83    1\n",
       "53    1\n",
       "70    1\n",
       "45    0\n",
       "44    0\n",
       "39    0\n",
       "22    0\n",
       "80    1\n",
       "10    0\n",
       "0     0\n",
       "18    0\n",
       "30    0\n",
       "73    1\n",
       "33    0\n",
       "90    1\n",
       "4     0\n",
       "76    1\n",
       "77    1\n",
       "12    0\n",
       "31    0\n",
       "55    1\n",
       "88    1\n",
       "26    0\n",
       "42    0\n",
       "69    1\n",
       "15    0\n",
       "40    0\n",
       "96    1\n",
       "9     0\n",
       "72    1\n",
       "dtype: int32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На первый взгляд неплохо. Посмотрим на accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Матрица ошибок\n",
      "[[15  2]\n",
      " [ 5  8]]\n",
      "Accuracy_test: 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "conf_matr_test = my_confusion_matrix(target_test.reset_index(drop=True), pred_test)\n",
    "print(\"Матрица ошибок\")\n",
    "print(conf_matr_test)\n",
    "print(\"Accuracy_test:\", accuracy(conf_matr_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7666666666666667"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(target_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И тут результат довольно приличный. Тем не менее, нужно обратить внимание на то, что разница между accuracy на тренировочной и на тестовой выборке достаточно большая. Из этого следует вывод, что модель переобучилась."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И всё же пока с этим ничего делать не будем. Попробуем достичь минимума при помощи градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 3. Градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, уравнение сигмоиды можно представить так:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "y_p = 1.0 / (1.0 + e^{-(b0 + b1 * X1 + b2 * X2 + b3 * X3 + b4 * X4)}\n",
    "\\end{align*}  \n",
    "\n",
    "Для каждого объекта, соответственно. Градиентный спуск поможет найти минимум. Задача в том, чтобы найти не просто 5 значений b,\n",
    "а 5 оптимальных значений для всех параметров х каждого объекта. Т.е. подобрать подходящие веса для модели.  \n",
    "Для начала переведем наши данные в нужный там тип - array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_tr = features_train.to_numpy()\n",
    "t_tr = target_train.to_numpy()\n",
    "\n",
    "f_tt = features_test.to_numpy()\n",
    "t_tt = target_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы в перспективе было удобно определять коэффициент b0, добавим к фичам новый столбец в начале - единицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 5.9, 3. , 4.2, 1.5],\n",
       "       [1. , 6.2, 2.9, 4.3, 1.3],\n",
       "       [1. , 7.7, 3. , 6.1, 2.3],\n",
       "       [1. , 6. , 2.9, 4.5, 1.5],\n",
       "       [1. , 6.8, 3.2, 5.9, 2.3]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = np.ones((f_tr.shape[0], 1))\n",
    "f_tr = np.hstack([ones, f_tr])\n",
    "f_tr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 6.3, 2.8, 5.1, 1.5],\n",
       "       [1. , 6.3, 2.9, 5.6, 1.8],\n",
       "       [1. , 6.9, 3.2, 5.7, 2.3],\n",
       "       [1. , 5.7, 3. , 4.2, 1.2],\n",
       "       [1. , 5.6, 2.7, 4.2, 1.3]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_tt = np.ones((f_tt.shape[0], 1))\n",
    "f_tt = np.hstack([ones_tt, f_tt])\n",
    "f_tt[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас 5 признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видоизменим функцию расчета предикта:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(coef, train):\n",
    "    predict = coef[0]* train[:, 0] + coef[1] * train[:, 1] + coef[2] * train[:, 2] + coef[3] * train[:, 3] + coef[4] * train[:, 4]\n",
    "    sigm = 1. / (1 + np.exp(-predict))\n",
    "    return sigm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь напишем функцию градиента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(start, l_rate, n_epochs, train, y):\n",
    "    cost = []\n",
    "    theta = start\n",
    "    for i in range(n_epochs):\n",
    "        sigm = predict(theta, train)\n",
    "        grad = np.matmul(train.T, (sigm - y)) / len(sigm)                # рассчитываем градиент\n",
    "        theta = theta - l_rate * grad                                    # перезаписываем веса\n",
    "        loss = - np.mean(np.log(sigm) * y + np.log(1 - sigm) * (1 - y))  # считаем потери\n",
    "        cost.append(loss)\n",
    "        i += 1\n",
    "    return theta, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для старта возьмем вручную подобранные веса из предыдущего шага:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.57813038, -1.30208057, -0.02651767,  1.57869983,  0.72461401])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_gd, cost_loss = gradient_descent(coef, 0.1, 100, f_tr, t_tr)\n",
    "coef_gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3827931064141419,\n",
       " 0.3815100429098301,\n",
       " 0.38023719320412247,\n",
       " 0.37897444012415443,\n",
       " 0.3777216681528722,\n",
       " 0.3764787634029759,\n",
       " 0.37524561359127206,\n",
       " 0.3740221080134261,\n",
       " 0.3728081375191135,\n",
       " 0.37160359448756053]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_loss[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предскажем вероятность попадания в класс 1 (порог поставим 0,5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted=0.349 [0]\n",
      "Predicted=0.269 [0]\n",
      "Predicted=0.649 [1]\n",
      "Predicted=0.431 [0]\n",
      "Predicted=0.812 [1]\n",
      "Predicted=0.493 [0]\n",
      "Predicted=0.704 [1]\n",
      "Predicted=0.738 [1]\n",
      "Predicted=0.446 [0]\n",
      "Predicted=0.560 [1]\n",
      "Predicted=0.341 [0]\n",
      "Predicted=0.623 [1]\n",
      "Predicted=0.252 [0]\n",
      "Predicted=0.621 [1]\n",
      "Predicted=0.436 [0]\n",
      "Predicted=0.272 [0]\n",
      "Predicted=0.643 [1]\n",
      "Predicted=0.216 [0]\n",
      "Predicted=0.667 [1]\n",
      "Predicted=0.459 [0]\n",
      "Predicted=0.221 [0]\n",
      "Predicted=0.367 [0]\n",
      "Predicted=0.268 [0]\n",
      "Predicted=0.369 [0]\n",
      "Predicted=0.260 [0]\n",
      "Predicted=0.798 [1]\n",
      "Predicted=0.428 [0]\n",
      "Predicted=0.830 [1]\n",
      "Predicted=0.294 [0]\n",
      "Predicted=0.599 [1]\n",
      "Predicted=0.788 [1]\n",
      "Predicted=0.734 [1]\n",
      "Predicted=0.836 [1]\n",
      "Predicted=0.229 [0]\n",
      "Predicted=0.918 [1]\n",
      "Predicted=0.813 [1]\n",
      "Predicted=0.377 [0]\n",
      "Predicted=0.868 [1]\n",
      "Predicted=0.682 [1]\n",
      "Predicted=0.631 [1]\n",
      "Predicted=0.570 [1]\n",
      "Predicted=0.420 [0]\n",
      "Predicted=0.749 [1]\n",
      "Predicted=0.148 [0]\n",
      "Predicted=0.810 [1]\n",
      "Predicted=0.748 [1]\n",
      "Predicted=0.677 [1]\n",
      "Predicted=0.236 [0]\n",
      "Predicted=0.805 [1]\n",
      "Predicted=0.801 [1]\n",
      "Predicted=0.782 [1]\n",
      "Predicted=0.780 [1]\n",
      "Predicted=0.278 [0]\n",
      "Predicted=0.140 [0]\n",
      "Predicted=0.309 [0]\n",
      "Predicted=0.718 [1]\n",
      "Predicted=0.208 [0]\n",
      "Predicted=0.305 [0]\n",
      "Predicted=0.424 [0]\n",
      "Predicted=0.730 [1]\n",
      "Predicted=0.518 [1]\n",
      "Predicted=0.756 [1]\n",
      "Predicted=0.847 [1]\n",
      "Predicted=0.810 [1]\n",
      "Predicted=0.631 [1]\n",
      "Predicted=0.592 [1]\n",
      "Predicted=0.776 [1]\n",
      "Predicted=0.211 [0]\n",
      "Predicted=0.773 [1]\n",
      "Predicted=0.773 [1]\n"
     ]
    }
   ],
   "source": [
    "pred_gd_train = []\n",
    "for row in features_train.to_numpy():\n",
    "    yhat_gd_tr = log_reg(row, coef_gd)\n",
    "    print(\"Predicted=%.3f [%d]\" % (yhat_gd_tr, round(yhat_gd_tr)))\n",
    "    pred_gd_train.append(round(yhat_gd_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим матрицу и посчитаем accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Матрица ошибок\n",
      "[[30  3]\n",
      " [ 0 37]]\n",
      "Accuracy_test: 0.9571428571428572\n"
     ]
    }
   ],
   "source": [
    "conf_matr_gd_tr = my_confusion_matrix(t_tr, pred_gd_train)\n",
    "print(\"Матрица ошибок\")\n",
    "print(conf_matr_gd_tr)\n",
    "print(\"Accuracy_test:\", accuracy(conf_matr_gd_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совсем немного ошибок и accuracy высокий. Что скажет тестовая выборка?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted=0.570 [1]\n",
      "Predicted=0.784 [1]\n",
      "Predicted=0.735 [1]\n",
      "Predicted=0.359 [0]\n",
      "Predicted=0.409 [0]\n",
      "Predicted=0.366 [0]\n",
      "Predicted=0.494 [0]\n",
      "Predicted=0.672 [1]\n",
      "Predicted=0.291 [0]\n",
      "Predicted=0.207 [0]\n",
      "Predicted=0.373 [0]\n",
      "Predicted=0.268 [0]\n",
      "Predicted=0.547 [1]\n",
      "Predicted=0.679 [1]\n",
      "Predicted=0.768 [1]\n",
      "Predicted=0.317 [0]\n",
      "Predicted=0.539 [1]\n",
      "Predicted=0.608 [1]\n",
      "Predicted=0.196 [0]\n",
      "Predicted=0.225 [0]\n",
      "Predicted=0.800 [1]\n",
      "Predicted=0.602 [1]\n",
      "Predicted=0.286 [0]\n",
      "Predicted=0.266 [0]\n",
      "Predicted=0.630 [1]\n",
      "Predicted=0.194 [0]\n",
      "Predicted=0.502 [1]\n",
      "Predicted=0.604 [1]\n",
      "Predicted=0.438 [0]\n",
      "Predicted=0.794 [1]\n"
     ]
    }
   ],
   "source": [
    "pred_gd_test = []\n",
    "for row in features_test.to_numpy():\n",
    "    yhat_gd_tt = log_reg(row, coef_gd)\n",
    "    print(\"Predicted=%.3f [%d]\" % (yhat_gd_tt, round(yhat_gd_tt)))\n",
    "    pred_gd_test.append(round(yhat_gd_tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Матрица ошибок\n",
      "[[15  2]\n",
      " [ 0 13]]\n",
      "Accuracy_test: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "conf_matr_gd_tt = my_confusion_matrix(target_test.to_numpy(), pred_gd_test)\n",
    "print(\"Матрица ошибок\")\n",
    "print(conf_matr_gd_tt)\n",
    "print(\"Accuracy_test:\", accuracy(conf_matr_gd_tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовых данных также отличный результат. Т.к. разница между долей верных ответов на тренировочной и тестовой выборках минимальна, можно сделать вывод, что модель не переобучилась.  \n",
    "Переходим к следующему шагу:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 4. Nesterov momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод \"nesterov momentum\" не только запоминает скорость на предыдущем шаге и добавляет в α раз меньшую величину на следующем шаге, но и поддерживает идею \"заглядывания вперёд\". Напишем функцию, оценивающую градиент сразу в позиции последующего шага, с помощью которой можно быстрее и четче найти точку в окрестности, где окажемся в следующий момент. Таким образом, бестрее доберемся до минимума:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nesterov_momentum(start, l_rate, n_epochs, train, y):\n",
    "    nm_cost = []\n",
    "    coef_nm = start\n",
    "    vel_new = np.zeros(5)\n",
    "    vel_old = np.zeros(5)\n",
    "    a = 0.97   # зададим коэффициент а, чтобы использовать как экспоненциально убывающий фактор (уменьшим вес старых значений градиента)\n",
    "    for i in range(n_epochs):\n",
    "        sigm = predict(coef_nm, train)\n",
    "        loss = - np.mean(np.log(sigm) * y + np.log(1 - sigm) * (1 - y))\n",
    "        nm_cost.append(loss)\n",
    "\n",
    "        sigm = predict(coef_nm - a * vel_new, train)\n",
    "        vel_new = (a * vel_new + l_rate * np.matmul((sigm - y), train))/len(sigm)\n",
    "        coef_nm -= vel_new\n",
    "        i += 1\n",
    "\n",
    "        vel_new = vel_old\n",
    "    return coef_nm, nm_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве старта снова возьмем вручную подобранные точки для логистической регрессии в переменной \"coef\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.30362818, -0.80180026, 0.55469071, 0.749991, -0.00459491]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.70540326, -1.51043065, -0.2927892 ,  1.91673383,  1.0396117 ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nm_coef, cost_nm = nesterov_momentum(coef, 0.02, 800, f_tr, t_tr)\n",
    "nm_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted=0.292 [0]\n",
      "Predicted=0.210 [0]\n",
      "Predicted=0.705 [1]\n",
      "Predicted=0.394 [0]\n",
      "Predicted=0.857 [1]\n",
      "Predicted=0.461 [0]\n",
      "Predicted=0.733 [1]\n",
      "Predicted=0.776 [1]\n",
      "Predicted=0.383 [0]\n",
      "Predicted=0.536 [1]\n",
      "Predicted=0.284 [0]\n",
      "Predicted=0.609 [1]\n",
      "Predicted=0.191 [0]\n",
      "Predicted=0.658 [1]\n",
      "Predicted=0.413 [0]\n",
      "Predicted=0.218 [0]\n",
      "Predicted=0.645 [1]\n",
      "Predicted=0.159 [0]\n",
      "Predicted=0.705 [1]\n",
      "Predicted=0.425 [0]\n",
      "Predicted=0.164 [0]\n",
      "Predicted=0.339 [0]\n",
      "Predicted=0.205 [0]\n",
      "Predicted=0.303 [0]\n",
      "Predicted=0.205 [0]\n",
      "Predicted=0.849 [1]\n",
      "Predicted=0.374 [0]\n",
      "Predicted=0.879 [1]\n",
      "Predicted=0.238 [0]\n",
      "Predicted=0.622 [1]\n",
      "Predicted=0.826 [1]\n",
      "Predicted=0.760 [1]\n",
      "Predicted=0.881 [1]\n",
      "Predicted=0.173 [0]\n",
      "Predicted=0.948 [1]\n",
      "Predicted=0.843 [1]\n",
      "Predicted=0.318 [0]\n",
      "Predicted=0.926 [1]\n",
      "Predicted=0.725 [1]\n",
      "Predicted=0.656 [1]\n",
      "Predicted=0.580 [1]\n",
      "Predicted=0.372 [0]\n",
      "Predicted=0.807 [1]\n",
      "Predicted=0.096 [0]\n",
      "Predicted=0.842 [1]\n",
      "Predicted=0.797 [1]\n",
      "Predicted=0.701 [1]\n",
      "Predicted=0.177 [0]\n",
      "Predicted=0.850 [1]\n",
      "Predicted=0.840 [1]\n",
      "Predicted=0.834 [1]\n",
      "Predicted=0.819 [1]\n",
      "Predicted=0.248 [0]\n",
      "Predicted=0.089 [0]\n",
      "Predicted=0.245 [0]\n",
      "Predicted=0.766 [1]\n",
      "Predicted=0.152 [0]\n",
      "Predicted=0.253 [0]\n",
      "Predicted=0.382 [0]\n",
      "Predicted=0.756 [1]\n",
      "Predicted=0.533 [1]\n",
      "Predicted=0.789 [1]\n",
      "Predicted=0.882 [1]\n",
      "Predicted=0.862 [1]\n",
      "Predicted=0.627 [1]\n",
      "Predicted=0.597 [1]\n",
      "Predicted=0.816 [1]\n",
      "Predicted=0.147 [0]\n",
      "Predicted=0.817 [1]\n",
      "Predicted=0.817 [1]\n"
     ]
    }
   ],
   "source": [
    "pred_nm_train = []\n",
    "for row in features_train.to_numpy():\n",
    "    yhat_nm_tr = log_reg(row, nm_coef)\n",
    "    print(\"Predicted=%.3f [%d]\" % (yhat_nm_tr, round(yhat_nm_tr)))\n",
    "    pred_nm_train.append(round(yhat_nm_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим матрицу и посчитаем accuracy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Матрица ошибок\n",
      "[[30  3]\n",
      " [ 0 37]]\n",
      "Accuracy_test: 0.9571428571428572\n"
     ]
    }
   ],
   "source": [
    "conf_matr_nm_tr = my_confusion_matrix(t_tr, pred_nm_train)\n",
    "print(\"Матрица ошибок\")\n",
    "print(conf_matr_nm_tr)\n",
    "print(\"Accuracy_test:\", accuracy(conf_matr_nm_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь доля правильных ответов такая же, как при градиентном спуске. Что скажет тестовая выборка?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted=0.573 [1]\n",
      "Predicted=0.823 [1]\n",
      "Predicted=0.778 [1]\n",
      "Predicted=0.290 [0]\n",
      "Predicted=0.365 [0]\n",
      "Predicted=0.326 [0]\n",
      "Predicted=0.500 [0]\n",
      "Predicted=0.724 [1]\n",
      "Predicted=0.251 [0]\n",
      "Predicted=0.148 [0]\n",
      "Predicted=0.371 [0]\n",
      "Predicted=0.216 [0]\n",
      "Predicted=0.563 [1]\n",
      "Predicted=0.707 [1]\n",
      "Predicted=0.817 [1]\n",
      "Predicted=0.276 [0]\n",
      "Predicted=0.545 [1]\n",
      "Predicted=0.614 [1]\n",
      "Predicted=0.154 [0]\n",
      "Predicted=0.170 [0]\n",
      "Predicted=0.855 [1]\n",
      "Predicted=0.605 [1]\n",
      "Predicted=0.242 [0]\n",
      "Predicted=0.212 [0]\n",
      "Predicted=0.675 [1]\n",
      "Predicted=0.137 [0]\n",
      "Predicted=0.477 [0]\n",
      "Predicted=0.647 [1]\n",
      "Predicted=0.397 [0]\n",
      "Predicted=0.854 [1]\n"
     ]
    }
   ],
   "source": [
    "pred_nm_test = []\n",
    "for row in features_test.to_numpy():\n",
    "    yhat_nm_tt = log_reg(row, nm_coef)\n",
    "    print(\"Predicted=%.3f [%d]\" % (yhat_nm_tt, round(yhat_nm_tt)))\n",
    "    pred_nm_test.append(round(yhat_nm_tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Матрица ошибок\n",
      "[[16  1]\n",
      " [ 0 13]]\n",
      "Accuracy_test: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "conf_matr_nm_tt = my_confusion_matrix(t_tt, pred_nm_test)\n",
    "print(\"Матрица ошибок\")\n",
    "print(conf_matr_nm_tt)\n",
    "print(\"Accuracy_test:\", accuracy(conf_matr_nm_tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy на тренировочных данных при использовании nesterov momentum точно такое же, как и при методе градиентного спуска. Вместе с тем, нельзя не отметить, что при использовании тестовых данных (которые модель еще не видела) результат оказался выше у метода nesterov momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 5. Метод rmsprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный метод позволяет также как и нестеров моментум использовать экспоненциально затухающее бегущее среднее, но при этом вместо полной суммы обновлений весов (которые обновляются часто) используется усреднённый по истории квадрат градиента.  \n",
    "Соответственно, мы лишь немного видоизменим функцию, которую писали для нестеров моментум:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsprop(start, l_rate, n_epochs, train, y):\n",
    "    coef_rmsp = start\n",
    "    grad_square = np.zeros(5)\n",
    "    grad = np.zeros(5)\n",
    "    rmsp_cost = []\n",
    "    a = 0.99\n",
    "    eps = 0.0000001     # добавим сглаживающий параметр, необходимый, чтобы избежать деления на 0\n",
    "    for i in range(n_epochs):\n",
    "        sigm = predict(coef_rmsp, train)\n",
    "        loss = - np.mean(np.log(sigm) * y + np.log(1 - sigm) * (1 - y))\n",
    "        rmsp_cost.append(loss)\n",
    "        \n",
    "        grad = np.matmul((sigm - y), train)/len(sigm)\n",
    "\n",
    "        grad_square = a * grad_square + (1 - a)  * grad ** 2\n",
    "\n",
    "        coef_rmsp -= l_rate * grad / np.sqrt(grad_square + eps)\n",
    "        i += 1\n",
    "    return coef_rmsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.77235683, -2.06380094, -2.4192069 ,  3.53262128,  3.82999739])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_rmsp = rmsprop(coef, 0.01, 500, f_tr, t_tr)\n",
    "coef_rmsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted=0.068 [0]\n",
      "Predicted=0.032 [0]\n",
      "Predicted=0.969 [1]\n",
      "Predicted=0.178 [0]\n",
      "Predicted=0.984 [1]\n",
      "Predicted=0.192 [0]\n",
      "Predicted=0.867 [1]\n",
      "Predicted=0.943 [1]\n",
      "Predicted=0.087 [0]\n",
      "Predicted=0.280 [0]\n",
      "Predicted=0.055 [0]\n",
      "Predicted=0.370 [0]\n",
      "Predicted=0.015 [0]\n",
      "Predicted=0.911 [1]\n",
      "Predicted=0.336 [0]\n",
      "Predicted=0.033 [0]\n",
      "Predicted=0.731 [1]\n",
      "Predicted=0.023 [0]\n",
      "Predicted=0.917 [1]\n",
      "Predicted=0.196 [0]\n",
      "Predicted=0.021 [0]\n",
      "Predicted=0.171 [0]\n",
      "Predicted=0.019 [0]\n",
      "Predicted=0.042 [0]\n",
      "Predicted=0.040 [0]\n",
      "Predicted=0.983 [1]\n",
      "Predicted=0.116 [0]\n",
      "Predicted=0.991 [1]\n",
      "Predicted=0.060 [0]\n",
      "Predicted=0.833 [1]\n",
      "Predicted=0.922 [1]\n",
      "Predicted=0.846 [1]\n",
      "Predicted=0.989 [1]\n",
      "Predicted=0.015 [0]\n",
      "Predicted=0.998 [1]\n",
      "Predicted=0.962 [1]\n",
      "Predicted=0.061 [0]\n",
      "Predicted=0.999 [1]\n",
      "Predicted=0.923 [1]\n",
      "Predicted=0.830 [1]\n",
      "Predicted=0.674 [1]\n",
      "Predicted=0.118 [0]\n",
      "Predicted=0.977 [1]\n",
      "Predicted=0.004 [0]\n",
      "Predicted=0.957 [1]\n",
      "Predicted=0.964 [1]\n",
      "Predicted=0.848 [1]\n",
      "Predicted=0.020 [0]\n",
      "Predicted=0.984 [1]\n",
      "Predicted=0.978 [1]\n",
      "Predicted=0.977 [1]\n",
      "Predicted=0.924 [1]\n",
      "Predicted=0.140 [0]\n",
      "Predicted=0.004 [0]\n",
      "Predicted=0.044 [0]\n",
      "Predicted=0.961 [1]\n",
      "Predicted=0.018 [0]\n",
      "Predicted=0.079 [0]\n",
      "Predicted=0.126 [0]\n",
      "Predicted=0.863 [1]\n",
      "Predicted=0.788 [1]\n",
      "Predicted=0.931 [1]\n",
      "Predicted=0.982 [1]\n",
      "Predicted=0.989 [1]\n",
      "Predicted=0.540 [1]\n",
      "Predicted=0.679 [1]\n",
      "Predicted=0.946 [1]\n",
      "Predicted=0.009 [0]\n",
      "Predicted=0.953 [1]\n",
      "Predicted=0.953 [1]\n"
     ]
    }
   ],
   "source": [
    "pred_rmsp_train = []\n",
    "for row in features_train.to_numpy():\n",
    "    yhat_rmsp_tr = log_reg(row, coef_rmsp)\n",
    "    print(\"Predicted=%.3f [%d]\" % (yhat_rmsp_tr, round(yhat_rmsp_tr)))\n",
    "    pred_rmsp_train.append(round(yhat_rmsp_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Матрица ошибок\n",
      "[[32  1]\n",
      " [ 0 37]]\n",
      "Accuracy_test: 0.9857142857142858\n"
     ]
    }
   ],
   "source": [
    "conf_matr_rmsp_tr = my_confusion_matrix(t_tr, pred_rmsp_train)\n",
    "print(\"Матрица ошибок\")\n",
    "print(conf_matr_rmsp_tr)\n",
    "print(\"Accuracy_test:\", accuracy(conf_matr_rmsp_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тест:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted=0.553 [1]\n",
      "Predicted=0.947 [1]\n",
      "Predicted=0.960 [1]\n",
      "Predicted=0.034 [0]\n",
      "Predicted=0.115 [0]\n",
      "Predicted=0.113 [0]\n",
      "Predicted=0.558 [1]\n",
      "Predicted=0.953 [1]\n",
      "Predicted=0.061 [0]\n",
      "Predicted=0.018 [0]\n",
      "Predicted=0.438 [0]\n",
      "Predicted=0.036 [0]\n",
      "Predicted=0.710 [1]\n",
      "Predicted=0.811 [1]\n",
      "Predicted=0.980 [1]\n",
      "Predicted=0.123 [0]\n",
      "Predicted=0.625 [1]\n",
      "Predicted=0.642 [1]\n",
      "Predicted=0.029 [0]\n",
      "Predicted=0.017 [0]\n",
      "Predicted=0.990 [1]\n",
      "Predicted=0.608 [1]\n",
      "Predicted=0.094 [0]\n",
      "Predicted=0.035 [0]\n",
      "Predicted=0.873 [1]\n",
      "Predicted=0.015 [0]\n",
      "Predicted=0.219 [0]\n",
      "Predicted=0.893 [1]\n",
      "Predicted=0.130 [0]\n",
      "Predicted=0.993 [1]\n"
     ]
    }
   ],
   "source": [
    "pred_rmsp_test = []\n",
    "for row in features_test.to_numpy():\n",
    "    yhat_rmsp_tt = log_reg(row, coef_rmsp)\n",
    "    print(\"Predicted=%.3f [%d]\" % (yhat_rmsp_tt, round(yhat_rmsp_tt)))\n",
    "    pred_rmsp_test.append(round(yhat_rmsp_tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Матрица ошибок\n",
      "[[15  2]\n",
      " [ 0 13]]\n",
      "Accuracy_test: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "conf_matr_rmsp_tt = my_confusion_matrix(t_tt, pred_rmsp_test)\n",
    "print(\"Матрица ошибок\")\n",
    "print(conf_matr_rmsp_tt)\n",
    "print(\"Accuracy_test:\", accuracy(conf_matr_rmsp_tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный метод показал наивысший результат при анализе доли правильных ответов на тренировочной выборке. Тем не менее, на тестовой выборке он показал результат идентичный градиентному спуску."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 6. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, цель данной работы - оптимизировать самостоятельно реализованную логистическую регрессию - достигнута.  \n",
    "Работа состояла из ряда задач, которые были взяты за основу плана проекта.  \n",
    "- Первой задачей  была реализация логистической регрессии. Нами были подобраны рандомным способом несколько вариантов коэффициентов для обучения модели. Самый лучший вариант коэффициентов был оставлен как основа для последующих методов оптимизации. И всё же рандомный метод перебора параметров был ожидаемо не самым лучшим, о чем свидетельствует достаточно низкий (в сравнении с остальными методами) показатель качества accuracy.  \n",
    "- В этой связи мы приступили к реализации второй задачи - обучить модель логистической регрессии при помощи метода градиентного спуска. Градиентный спуск показал хороший результат, поэтому он также был зафиксирован и взят за образец.  \n",
    "- Метод \"nesterov momentum\" (задача №3) показал себя чуть лучше, чем градиентный спуск: при вычислении accuracy для тренировочной выборки результат был одинаков, но при определении доли правильных ответов на тестовой выборке этот метод дал результат лучше.  \n",
    "- Последней задачей стала реализация метода rmsprop. При оптимизации работы модели данным методом был достигнут наивысший accuracy на обучающей выборке, однако на тестовой результат был аналогичен результату градинтного спуска.\n",
    "\n",
    "Таким образом, можно подвести итог, что цель работы выполнена, модель обучена, методы реализованы. Лучше всего в данном случае на тестовой выборке показал себя метод nesterov momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}